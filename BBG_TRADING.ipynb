{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  142 of 142 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "['TWTR', 'FB', 'VIAC', 'ANTM']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1. Expanded stock universe\n",
    "industries = {\n",
    "    'Technology': ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'NVDA', 'ADBE', 'INTC', 'CSCO', 'CRM', 'ORCL', 'TXN', 'IBM', 'HPQ', 'QCOM', 'MU'],\n",
    "    'Consumer Staples': ['PEP', 'KO', 'PG', 'MDLZ', 'GIS', 'HSY', 'CL', 'K', 'WMT', 'COST', 'TGT', 'KR', 'SYY', 'TSN'],\n",
    "    'Healthcare': ['PFE', 'MRK', 'JNJ', 'UNH', 'ABT', 'ABBV', 'GILD', 'BIIB', 'LLY', 'BMY', 'DHR', 'TMO', 'CVS', 'ANTM'],\n",
    "    'Financials': ['JPM', 'GS', 'MS', 'BAC', 'C', 'AXP', 'USB', 'BK', 'WFC', 'BLK', 'TROW', 'SPGI', 'SCHW', 'V', 'MA'],\n",
    "    'Energy': ['XOM', 'CVX', 'COP', 'SLB', 'PSX', 'MPC', 'EOG', 'HAL', 'BKR', 'VLO', 'OXY', 'HES'],\n",
    "    'Industrials': ['BA', 'CAT', 'GE', 'MMM', 'DE', 'UPS', 'FDX', 'LMT', 'RTX', 'HON', 'ETN', 'GD', 'EMR'],\n",
    "    'Utilities': ['NEE', 'DUK', 'SO', 'D', 'EXC', 'AEP', 'XEL', 'ES', 'PEG', 'WEC', 'SRE', 'PCG'],\n",
    "    'Consumer Discretionary': ['TSLA', 'HD', 'NKE', 'SBUX', 'MCD', 'LOW', 'TJX', 'LVS', 'MAR', 'ROST', 'DLTR', 'YUM'],\n",
    "    'Real Estate': ['AMT', 'PLD', 'EQIX', 'PSA', 'DLR', 'VTR', 'SPG', 'O', 'SBAC', 'CCI', 'WY', 'EQR'],\n",
    "    'Communication Services': ['FB', 'GOOGL', 'DIS', 'CMCSA', 'VZ', 'T', 'NFLX', 'TMUS', 'CHTR', 'TWTR', 'VIAC'],\n",
    "    'Materials': ['LIN', 'APD', 'SHW', 'ECL', 'PPG', 'NUE', 'DD', 'FCX', 'VMC', 'MLM', 'IP', 'LYB']\n",
    "}\n",
    "\n",
    "# Combine all stocks\n",
    "stocks = [ticker for industry in industries.values() for ticker in industry]\n",
    "\n",
    "# 2. Fetch historical data for the last 6 months (or longer for correlation computation)\n",
    "data = yf.download(stocks, start='2024-01-01', end='2024-10-18')['Adj Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-01-02 00:00:00+00:00         NaN\n",
       "2024-01-03 00:00:00+00:00    0.005403\n",
       "2024-01-04 00:00:00+00:00   -0.013328\n",
       "2024-01-05 00:00:00+00:00    0.003268\n",
       "2024-01-08 00:00:00+00:00   -0.001737\n",
       "                               ...   \n",
       "2024-10-11 00:00:00+00:00    0.002717\n",
       "2024-10-14 00:00:00+00:00   -0.001626\n",
       "2024-10-15 00:00:00+00:00    0.015741\n",
       "2024-10-16 00:00:00+00:00    0.009084\n",
       "2024-10-17 00:00:00+00:00   -0.001942\n",
       "Name: KR, Length: 201, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['KR'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-01-02 00:00:00+00:00   -0.000300\n",
       "2024-01-03 00:00:00+00:00   -0.014836\n",
       "2024-01-04 00:00:00+00:00   -0.011409\n",
       "2024-01-05 00:00:00+00:00   -0.005385\n",
       "2024-01-08 00:00:00+00:00    0.005152\n",
       "                               ...   \n",
       "2024-10-11 00:00:00+00:00    0.000283\n",
       "2024-10-14 00:00:00+00:00    0.005647\n",
       "2024-10-15 00:00:00+00:00   -0.003229\n",
       "2024-10-16 00:00:00+00:00   -0.004507\n",
       "2024-10-17 00:00:00+00:00         NaN\n",
       "Name: GIS, Length: 201, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['GIS'].pct_change().shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('AEP', 'ES'),\n",
       " ('BK', 'BAC'),\n",
       " ('BK', 'BLK'),\n",
       " ('BK', 'WFC'),\n",
       " ('C', 'BK'),\n",
       " ('CAT', 'EMR'),\n",
       " ('CCI', 'SBAC'),\n",
       " ('CRM', 'ADBE'),\n",
       " ('CSCO', 'TXN'),\n",
       " ('D', 'ES'),\n",
       " ('FDX', 'ETN'),\n",
       " ('LMT', 'HON'),\n",
       " ('MS', 'C'),\n",
       " ('MS', 'SCHW'),\n",
       " ('NEE', 'EXC'),\n",
       " ('NFLX', 'DIS'),\n",
       " ('NVDA', 'QCOM'),\n",
       " ('O', 'AMT'),\n",
       " ('O', 'SBAC'),\n",
       " ('PLD', 'AMT'),\n",
       " ('PLD', 'SBAC'),\n",
       " ('SBAC', 'PLD'),\n",
       " ('SRE', 'ES'),\n",
       " ('TXN', 'QCOM'),\n",
       " ('USB', 'SCHW'),\n",
       " ('V', 'SCHW'),\n",
       " ('WEC', 'DUK'),\n",
       " ('WEC', 'ES'),\n",
       " ('WEC', 'EXC'),\n",
       " ('XEL', 'ES')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previous_pairs = \n",
    "set(selected_pairs) - set(check_correlation_threshold(data, selected_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NVDA', 'QCOM'),\n",
       " ('CSCO', 'TXN'),\n",
       " ('CRM', 'ADBE'),\n",
       " ('TXN', 'QCOM'),\n",
       " ('LLY', 'TMO'),\n",
       " ('MS', 'C'),\n",
       " ('MS', 'SCHW'),\n",
       " ('C', 'BK'),\n",
       " ('USB', 'SCHW'),\n",
       " ('BK', 'BAC'),\n",
       " ('BK', 'WFC'),\n",
       " ('BK', 'BLK'),\n",
       " ('V', 'SCHW'),\n",
       " ('CAT', 'EMR'),\n",
       " ('FDX', 'CAT'),\n",
       " ('FDX', 'ETN'),\n",
       " ('LMT', 'HON'),\n",
       " ('NEE', 'EXC'),\n",
       " ('D', 'DUK'),\n",
       " ('D', 'EXC'),\n",
       " ('D', 'AEP'),\n",
       " ('D', 'ES'),\n",
       " ('AEP', 'DUK'),\n",
       " ('AEP', 'EXC'),\n",
       " ('AEP', 'ES'),\n",
       " ('XEL', 'EXC'),\n",
       " ('XEL', 'AEP'),\n",
       " ('XEL', 'ES'),\n",
       " ('XEL', 'WEC'),\n",
       " ('XEL', 'SRE'),\n",
       " ('WEC', 'DUK'),\n",
       " ('WEC', 'EXC'),\n",
       " ('WEC', 'ES'),\n",
       " ('SRE', 'EXC'),\n",
       " ('SRE', 'ES'),\n",
       " ('PLD', 'AMT'),\n",
       " ('PLD', 'O'),\n",
       " ('PLD', 'SBAC'),\n",
       " ('O', 'AMT'),\n",
       " ('O', 'SBAC'),\n",
       " ('SBAC', 'PLD'),\n",
       " ('SBAC', 'EQR'),\n",
       " ('CCI', 'PLD'),\n",
       " ('CCI', 'SBAC'),\n",
       " ('NFLX', 'DIS')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlated Pairs Above Threshold:\n",
      "NVDA (correlated with QCOM) - correlation a->lagged_b: -0.41, b->lagged_a: -0.12\n",
      "ADBE (correlated with CRM) - correlation a->lagged_b: -0.34, b->lagged_a: -0.46\n",
      "CSCO (correlated with TXN) - correlation a->lagged_b: -0.45, b->lagged_a: -0.16\n",
      "CRM (correlated with ADBE) - correlation a->lagged_b: -0.46, b->lagged_a: -0.34\n",
      "TXN (correlated with CSCO) - correlation a->lagged_b: -0.16, b->lagged_a: -0.45\n",
      "TXN (correlated with QCOM) - correlation a->lagged_b: -0.54, b->lagged_a: -0.06\n",
      "QCOM (correlated with NVDA) - correlation a->lagged_b: -0.12, b->lagged_a: -0.41\n",
      "QCOM (correlated with TXN) - correlation a->lagged_b: -0.06, b->lagged_a: -0.54\n",
      "PFE (correlated with DHR) - correlation a->lagged_b: 0.15, b->lagged_a: -0.41\n",
      "UNH (correlated with DHR) - correlation a->lagged_b: 0.05, b->lagged_a: 0.40\n",
      "DHR (correlated with PFE) - correlation a->lagged_b: -0.41, b->lagged_a: 0.15\n",
      "DHR (correlated with UNH) - correlation a->lagged_b: 0.40, b->lagged_a: 0.05\n",
      "MS (correlated with C) - correlation a->lagged_b: -0.50, b->lagged_a: -0.25\n",
      "MS (correlated with BLK) - correlation a->lagged_b: 0.22, b->lagged_a: -0.42\n",
      "MS (correlated with SPGI) - correlation a->lagged_b: -0.03, b->lagged_a: -0.50\n",
      "MS (correlated with SCHW) - correlation a->lagged_b: 0.56, b->lagged_a: -0.03\n",
      "BAC (correlated with BK) - correlation a->lagged_b: -0.05, b->lagged_a: 0.49\n",
      "C (correlated with MS) - correlation a->lagged_b: -0.25, b->lagged_a: -0.50\n",
      "C (correlated with BK) - correlation a->lagged_b: -0.43, b->lagged_a: 0.11\n",
      "USB (correlated with BLK) - correlation a->lagged_b: 0.30, b->lagged_a: -0.44\n",
      "USB (correlated with SCHW) - correlation a->lagged_b: 0.43, b->lagged_a: 0.10\n",
      "BK (correlated with BAC) - correlation a->lagged_b: 0.49, b->lagged_a: -0.05\n",
      "BK (correlated with C) - correlation a->lagged_b: 0.11, b->lagged_a: -0.43\n",
      "BK (correlated with WFC) - correlation a->lagged_b: 0.42, b->lagged_a: 0.09\n",
      "BK (correlated with BLK) - correlation a->lagged_b: 0.43, b->lagged_a: -0.02\n",
      "BK (correlated with SCHW) - correlation a->lagged_b: 0.38, b->lagged_a: 0.45\n",
      "WFC (correlated with BK) - correlation a->lagged_b: 0.09, b->lagged_a: 0.42\n",
      "BLK (correlated with MS) - correlation a->lagged_b: -0.42, b->lagged_a: 0.22\n",
      "BLK (correlated with USB) - correlation a->lagged_b: -0.44, b->lagged_a: 0.30\n",
      "BLK (correlated with BK) - correlation a->lagged_b: -0.02, b->lagged_a: 0.43\n",
      "SPGI (correlated with MS) - correlation a->lagged_b: -0.50, b->lagged_a: -0.03\n",
      "SCHW (correlated with MS) - correlation a->lagged_b: -0.03, b->lagged_a: 0.56\n",
      "SCHW (correlated with USB) - correlation a->lagged_b: 0.10, b->lagged_a: 0.43\n",
      "SCHW (correlated with BK) - correlation a->lagged_b: 0.45, b->lagged_a: 0.38\n",
      "SCHW (correlated with V) - correlation a->lagged_b: 0.08, b->lagged_a: 0.44\n",
      "V (correlated with SCHW) - correlation a->lagged_b: 0.44, b->lagged_a: 0.08\n",
      "CAT (correlated with EMR) - correlation a->lagged_b: -0.42, b->lagged_a: -0.12\n",
      "DE (correlated with EMR) - correlation a->lagged_b: -0.41, b->lagged_a: -0.09\n",
      "FDX (correlated with ETN) - correlation a->lagged_b: -0.40, b->lagged_a: 0.00\n",
      "LMT (correlated with HON) - correlation a->lagged_b: -0.42, b->lagged_a: -0.21\n",
      "HON (correlated with LMT) - correlation a->lagged_b: -0.21, b->lagged_a: -0.42\n",
      "ETN (correlated with FDX) - correlation a->lagged_b: 0.00, b->lagged_a: -0.40\n",
      "EMR (correlated with CAT) - correlation a->lagged_b: -0.12, b->lagged_a: -0.42\n",
      "EMR (correlated with DE) - correlation a->lagged_b: -0.09, b->lagged_a: -0.41\n",
      "NEE (correlated with EXC) - correlation a->lagged_b: 0.46, b->lagged_a: 0.01\n",
      "DUK (correlated with WEC) - correlation a->lagged_b: 0.30, b->lagged_a: 0.42\n",
      "SO (correlated with ES) - correlation a->lagged_b: 0.40, b->lagged_a: 0.10\n",
      "D (correlated with ES) - correlation a->lagged_b: 0.54, b->lagged_a: -0.08\n",
      "EXC (correlated with NEE) - correlation a->lagged_b: 0.01, b->lagged_a: 0.46\n",
      "EXC (correlated with WEC) - correlation a->lagged_b: 0.09, b->lagged_a: 0.40\n",
      "AEP (correlated with ES) - correlation a->lagged_b: 0.45, b->lagged_a: 0.19\n",
      "XEL (correlated with ES) - correlation a->lagged_b: 0.41, b->lagged_a: 0.27\n",
      "ES (correlated with SO) - correlation a->lagged_b: 0.10, b->lagged_a: 0.40\n",
      "ES (correlated with D) - correlation a->lagged_b: -0.08, b->lagged_a: 0.54\n",
      "ES (correlated with AEP) - correlation a->lagged_b: 0.19, b->lagged_a: 0.45\n",
      "ES (correlated with XEL) - correlation a->lagged_b: 0.27, b->lagged_a: 0.41\n",
      "ES (correlated with WEC) - correlation a->lagged_b: 0.17, b->lagged_a: 0.51\n",
      "ES (correlated with SRE) - correlation a->lagged_b: 0.15, b->lagged_a: 0.42\n",
      "WEC (correlated with DUK) - correlation a->lagged_b: 0.42, b->lagged_a: 0.30\n",
      "WEC (correlated with EXC) - correlation a->lagged_b: 0.40, b->lagged_a: 0.09\n",
      "WEC (correlated with ES) - correlation a->lagged_b: 0.51, b->lagged_a: 0.17\n",
      "SRE (correlated with ES) - correlation a->lagged_b: 0.42, b->lagged_a: 0.15\n",
      "AMT (correlated with PLD) - correlation a->lagged_b: 0.01, b->lagged_a: 0.52\n",
      "AMT (correlated with O) - correlation a->lagged_b: -0.06, b->lagged_a: 0.47\n",
      "PLD (correlated with AMT) - correlation a->lagged_b: 0.52, b->lagged_a: 0.01\n",
      "PLD (correlated with SBAC) - correlation a->lagged_b: 0.51, b->lagged_a: 0.15\n",
      "O (correlated with AMT) - correlation a->lagged_b: 0.47, b->lagged_a: -0.06\n",
      "O (correlated with SBAC) - correlation a->lagged_b: 0.60, b->lagged_a: 0.04\n",
      "SBAC (correlated with PLD) - correlation a->lagged_b: 0.15, b->lagged_a: 0.51\n",
      "SBAC (correlated with O) - correlation a->lagged_b: 0.04, b->lagged_a: 0.60\n",
      "SBAC (correlated with CCI) - correlation a->lagged_b: 0.19, b->lagged_a: 0.42\n",
      "CCI (correlated with SBAC) - correlation a->lagged_b: 0.42, b->lagged_a: 0.19\n",
      "DIS (correlated with NFLX) - correlation a->lagged_b: -0.13, b->lagged_a: -0.51\n",
      "NFLX (correlated with DIS) - correlation a->lagged_b: -0.51, b->lagged_a: -0.13\n",
      "APD (correlated with NUE) - correlation a->lagged_b: -0.02, b->lagged_a: -0.43\n",
      "NUE (correlated with APD) - correlation a->lagged_b: -0.43, b->lagged_a: -0.02\n",
      "\n",
      "Optimized Portfolio Allocation (in dollars):\n",
      "NVDA: $84788.34\n",
      "BK: $55478.24\n",
      "SO: $248776.95\n",
      "\n",
      "Selected Correlated Pairs for Trading:\n",
      "NVDA (based on QCOM)\n",
      "CRM (based on ADBE)\n",
      "TXN (based on QCOM)\n",
      "DHR (based on UNH)\n",
      "MS (based on SCHW)\n",
      "USB (based on SCHW)\n",
      "BK (based on BAC)\n",
      "BK (based on WFC)\n",
      "BK (based on BLK)\n",
      "SCHW (based on BK)\n",
      "V (based on SCHW)\n",
      "NEE (based on EXC)\n",
      "SO (based on ES)\n",
      "D (based on ES)\n",
      "AEP (based on ES)\n",
      "XEL (based on ES)\n",
      "WEC (based on DUK)\n",
      "WEC (based on EXC)\n",
      "WEC (based on ES)\n",
      "SRE (based on ES)\n",
      "\n",
      "Pairs to monitor for future rebalancing:\n",
      "Pair: NVDA and QCOM\n",
      "Pair: CRM and ADBE\n",
      "Pair: TXN and QCOM\n",
      "Pair: DHR and UNH\n",
      "Pair: MS and SCHW\n",
      "Pair: USB and SCHW\n",
      "Pair: BK and BAC\n",
      "Pair: BK and WFC\n",
      "Pair: BK and BLK\n",
      "Pair: SCHW and BK\n",
      "Pair: V and SCHW\n",
      "Pair: NEE and EXC\n",
      "Pair: SO and ES\n",
      "Pair: D and ES\n",
      "Pair: AEP and ES\n",
      "Pair: XEL and ES\n",
      "Pair: WEC and DUK\n",
      "Pair: WEC and EXC\n",
      "Pair: WEC and ES\n",
      "Pair: SRE and ES\n"
     ]
    }
   ],
   "source": [
    "correlation_threshold = 0.40\n",
    "principal = 500000\n",
    "\n",
    "# 3. Define lagged correlation function for signals\n",
    "def ew_lagged_return_correlation(stock_a, stock_b, span=60):\n",
    "    \"\"\"Calculates the 1-day lagged exponential weighted correlation between two stock price series.\"\"\"\n",
    "    # Calculate daily returns\n",
    "    returns_a = stock_a.pct_change()\n",
    "    returns_b = stock_b.pct_change()\n",
    "\n",
    "    # Calculate lagged returns\n",
    "    lagged_returns_a = returns_a.shift(1)\n",
    "    lagged_returns_b = returns_b.shift(1)\n",
    "\n",
    "    # Calculate exponentially weighted moving averages for lagged correlations\n",
    "    correlation_a_with_lagged_b = returns_a.ewm(span=span).corr(lagged_returns_b)\n",
    "    correlation_b_with_lagged_a = returns_b.ewm(span=span).corr(lagged_returns_a)\n",
    "\n",
    "    return correlation_a_with_lagged_b, correlation_b_with_lagged_a\n",
    "\n",
    "# 4. Generate signals based on lagged asset returns and correlation\n",
    "def generate_lagged_signals(data, correlation_threshold=correlation_threshold, span=30):\n",
    "    \"\"\"Generates signals based on lagged asset return and correlation.\"\"\"\n",
    "    signals = pd.Series(index=data.columns)\n",
    "    selected_pairs = []\n",
    "    selected_non_lagged_stocks = []\n",
    "\n",
    "    print(\"\\nCorrelated Pairs Above Threshold:\")\n",
    "    for industry_name, industry_stocks in industries.items():\n",
    "        for stock_a in industry_stocks:\n",
    "            for stock_b in industry_stocks:\n",
    "                if stock_a != stock_b:\n",
    "                    # Calculate 1-day lagged return correlations\n",
    "                    corr_a_with_lagged_b, corr_b_with_lagged_a = ew_lagged_return_correlation(data[stock_a], data[stock_b], span=span)\n",
    "\n",
    "                    # Today's correlation values\n",
    "                    correlation_today_a_lag_b = corr_a_with_lagged_b.iloc[-1]\n",
    "                    correlation_today_b_lag_a = corr_b_with_lagged_a.iloc[-1]\n",
    "\n",
    "                    # Apply the trading rules based on correlation values\n",
    "                    if abs(correlation_today_a_lag_b) > correlation_threshold or abs(correlation_today_b_lag_a) > correlation_threshold:\n",
    "                        # Print the correlated pair\n",
    "                        print(f\"{stock_a} (correlated with {stock_b}) - correlation a->lagged_b: {correlation_today_a_lag_b:.2f}, b->lagged_a: {correlation_today_b_lag_a:.2f}\")\n",
    "\n",
    "                        # Use the lagged return of stock_b\n",
    "                        lagged_return_b = data[stock_b].pct_change().shift(1).iloc[-1]\n",
    "\n",
    "                        # Case 1: Positive correlation and lagged return positive -> go long\n",
    "                        if correlation_today_a_lag_b > correlation_threshold and lagged_return_b > 0:\n",
    "                            signals[stock_a] = 1\n",
    "                            selected_pairs.append((stock_a, stock_b))\n",
    "                            selected_non_lagged_stocks.append(stock_a)\n",
    "\n",
    "                        # Case 2: Negative correlation and lagged return negative -> go long\n",
    "                        elif correlation_today_a_lag_b < -correlation_threshold and lagged_return_b < 0:\n",
    "                            signals[stock_a] = 1\n",
    "                            selected_pairs.append((stock_a, stock_b))\n",
    "                            selected_non_lagged_stocks.append(stock_a)\n",
    "\n",
    "                        # Case 3: Do nothing when the other conditions are not met\n",
    "                        else:\n",
    "                            signals[stock_a] = 0\n",
    "\n",
    "    return signals, selected_pairs, selected_non_lagged_stocks\n",
    "\n",
    "# 5. Mean-Variance Optimization Function\n",
    "def mean_variance_optimizer(returns):\n",
    "    \"\"\"Optimizes the portfolio weights to achieve the best risk-return trade-off.\"\"\"\n",
    "    mean_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    "\n",
    "    # Number of assets\n",
    "    num_assets = len(mean_returns)\n",
    "\n",
    "    # Objective Function: Negative Sharpe Ratio\n",
    "    def portfolio_performance(weights):\n",
    "        \"\"\"Calculates portfolio performance.\"\"\"\n",
    "        portfolio_return = np.dot(weights, mean_returns)\n",
    "        portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return -portfolio_return / portfolio_risk  # Minimize negative Sharpe ratio\n",
    "\n",
    "    # Constraints: sum of weights = 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "    # Bounds: weights between 0 and 1 (long-only)\n",
    "    bounds = tuple((0, 1) for _ in range(num_assets))\n",
    "\n",
    "    # Initial guess: Equal weights\n",
    "    initial_weights = num_assets * [1. / num_assets]\n",
    "\n",
    "    # Optimize portfolio using SLSQP\n",
    "    optimized = minimize(portfolio_performance, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return optimized.x\n",
    "\n",
    "# 6. Today's trading signals based on lagged assets and filtered for optimization\n",
    "def trade_today(data, principal=100000, correlation_threshold=correlation_threshold):\n",
    "    \"\"\"Generates signals for trading today and applies mean-variance optimization.\"\"\"\n",
    "    # Generate signals based on lagged asset strategy\n",
    "    signals, selected_pairs, selected_non_lagged_stocks = generate_lagged_signals(data, correlation_threshold)\n",
    "\n",
    "    # Filter the returns data to only include selected non-lagged stocks\n",
    "    selected_data = data[selected_non_lagged_stocks]\n",
    "    \n",
    "    # Calculate returns over the last 6 months for the selected stocks (for mean-variance optimization)\n",
    "    six_month_returns = selected_data.pct_change().dropna()\n",
    "\n",
    "    # Optimize portfolio weights based on the selected non-lagged stocks\n",
    "    optimized_weights = mean_variance_optimizer(six_month_returns)\n",
    "\n",
    "    # Calculate dollar allocation for each asset\n",
    "    allocation = {stock: weight * principal for stock, weight in zip(selected_non_lagged_stocks, optimized_weights) if weight > 0.001}\n",
    "\n",
    "    return allocation, selected_pairs\n",
    "\n",
    "# 7. Rebalancing function: check correlations for future rebalancing\n",
    "def check_correlation_threshold(data, selected_pairs, correlation_threshold=correlation_threshold, span=30):\n",
    "    \"\"\"Checks if the selected pairs have dropped below the correlation threshold.\"\"\"\n",
    "    dropped_pairs = []\n",
    "    for stock_a, stock_b in selected_pairs:\n",
    "        # Recompute the rolling correlation\n",
    "        corr_a_with_lagged_b, corr_b_with_lagged_a = ew_lagged_return_correlation(data[stock_a], data[stock_b], span=span)\n",
    "        \n",
    "        # Today's correlation values\n",
    "        correlation_today_a_lag_b = corr_a_with_lagged_b.iloc[-1]\n",
    "        correlation_today_b_lag_a = corr_b_with_lagged_a.iloc[-1]\n",
    "\n",
    "        # Check if either correlation has dropped below the threshold\n",
    "        if abs(correlation_today_a_lag_b) < correlation_threshold and abs(correlation_today_b_lag_a) < correlation_threshold:\n",
    "            dropped_pairs.append((stock_a, stock_b))\n",
    "\n",
    "    return dropped_pairs\n",
    "\n",
    "# 8. Run today's trade and get the results\n",
    "allocation, selected_pairs = trade_today(data, principal=principal)\n",
    "\n",
    "# Output: Print the allocation and pairs for the next rebalancing\n",
    "print(\"\\nOptimized Portfolio Allocation (in dollars):\")\n",
    "for stock, alloc in allocation.items():\n",
    "    print(f\"{stock}: ${alloc:.2f}\")\n",
    "\n",
    "print(\"\\nSelected Correlated Pairs for Trading:\")\n",
    "for stock_a, stock_b in selected_pairs:\n",
    "    print(f\"{stock_a} (based on {stock_b})\")\n",
    "\n",
    "# Output of selected pairs for future use\n",
    "print(\"\\nPairs to monitor for future rebalancing:\")\n",
    "for stock_a, stock_b in selected_pairs:\n",
    "    print(f\"Pair: {stock_a} and {stock_b}\")\n",
    "\n",
    "# # 9. Optional: Check if correlations have dropped below threshold for rebalancing\n",
    "# dropped_pairs = check_correlation_threshold(data, selected_pairs)\n",
    "# if dropped_pairs:\n",
    "#     print(\"\\nPairs to drop (correlation below threshold):\")\n",
    "#     for stock_a, stock_b in dropped_pairs:\n",
    "#         print(f\"{stock_a} (correlated with {stock_b})\")\n",
    "# else:\n",
    "#     print(\"\\nNo pairs to drop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized Portfolio Allocation (in dollars):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "476911.3920632361"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output: Print the allocation and pairs for the next rebalancing\n",
    "print(\"\\nOptimized Portfolio Allocation (in dollars):\")\n",
    "tmp = 0\n",
    "for stock, alloc in allocation.items():\n",
    "    tmp += alloc\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  6 of 6 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Weights: [0.08631445 0.42526524 0.13584154 0.12507876 0.07977838 0.14772163]\n",
      "Expected Annual Return: 2.618655976471768\n",
      "Expected Annual Volatility: 0.6308087017574668\n",
      "Sharpe Ratio: 4.151267998009621\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "stocks = ['ASTS', 'LUMN', 'SMMT', 'VKTX', '196170.KQ', '0020.HK']\n",
    "\n",
    "# Download the adjusted close price data for the last year\n",
    "end_date = \"2024-10-09\"\n",
    "start_date = \"2023-10-09\"\n",
    "data = yf.download(stocks, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "# Drop any rows with missing data\n",
    "data = data.dropna()\n",
    "\n",
    "# Calculate daily returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Define a function to calculate portfolio performance\n",
    "def portfolio_performance(weights, returns):\n",
    "    portfolio_return = np.sum(returns.mean() * weights) * 252\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n",
    "    sharpe_ratio = portfolio_return / portfolio_volatility\n",
    "    return portfolio_return, portfolio_volatility, sharpe_ratio\n",
    "\n",
    "# Define the objective function (negative Sharpe ratio for minimization)\n",
    "def negative_sharpe_ratio(weights, returns):\n",
    "    return -portfolio_performance(weights, returns)[2]\n",
    "\n",
    "# Constraints: sum of weights is 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "\n",
    "# Bounds: each weight is between 0 and 1\n",
    "bounds = [(0, 1)] * len(stocks)\n",
    "\n",
    "# Initial guess (equal distribution)\n",
    "initial_weights = [1 / len(stocks)] * len(stocks)\n",
    "\n",
    "# Optimize the portfolio for maximum Sharpe ratio\n",
    "optimized_result = minimize(negative_sharpe_ratio, initial_weights, args=(returns,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Get the optimized weights and performance metrics\n",
    "optimized_weights = optimized_result.x\n",
    "optimized_return, optimized_volatility, optimized_sharpe_ratio = portfolio_performance(optimized_weights, returns)\n",
    "\n",
    "# Display results\n",
    "print(\"Optimized Weights:\", optimized_weights)\n",
    "print(\"Expected Annual Return:\", optimized_return)\n",
    "print(\"Expected Annual Volatility:\", optimized_volatility)\n",
    "print(\"Sharpe Ratio:\", optimized_sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43157.22566575, 212632.61880221,  67920.77019487,  62539.37806597,\n",
       "        39889.18991862,  73860.81735258])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "optimized_weights * 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sis_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
